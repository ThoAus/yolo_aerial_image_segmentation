{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0339b03",
   "metadata": {},
   "source": [
    "# 00 - Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e944b476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acec8ac4",
   "metadata": {},
   "source": [
    "# 01 - Training\n",
    "\n",
    "https://docs.ultralytics.com/modes/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd8f55b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.143 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.109  Python-3.12.4 torch-2.6.0+cpu CPU (AMD Ryzen 7 PRO 7840HS w/ Radeon 780M Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=segment, mode=train, model=yolo11m-seg.pt, data=config/config_train.yaml, epochs=3, time=None, patience=0, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs\\segment\\train2\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  1    111872  ultralytics.nn.modules.block.C3k2            [128, 256, 1, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  1    444928  ultralytics.nn.modules.block.C3k2            [256, 512, 1, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    542720  ultralytics.nn.modules.block.C3k2            [1024, 256, 1, True]          \n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
      " 23        [16, 19, 22]  1   3718774  ultralytics.nn.modules.head.Segment          [2, 32, 256, [256, 512, 512]] \n",
      "YOLO11m-seg summary: 253 layers, 22,360,758 parameters, 22,360,742 gradients, 123.6 GFLOPs\n",
      "\n",
      "Transferred 705/711 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\thoma\\Documents\\GitHub\\WING_YOLO\\dataset\\labels\\train... 200 images, 53 backgrounds, 0 corrupt: 100%|██████████| 200/200 [00:00<00:00, 363.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\thoma\\Documents\\GitHub\\WING_YOLO\\dataset\\labels\\train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\thoma\\Documents\\GitHub\\WING_YOLO\\dataset\\labels\\val... 50 images, 12 backgrounds, 0 corrupt: 100%|██████████| 50/50 [00:00<00:00, 433.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\thoma\\Documents\\GitHub\\WING_YOLO\\dataset\\labels\\val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\segment\\train2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 115 weight(decay=0.0), 126 weight(decay=0.0005), 125 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\segment\\train2\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3         0G      1.169      2.908      2.145      1.325         80        640: 100%|██████████| 13/13 [04:13<00:00, 19.49s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:25<00:00, 12.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         50        268      0.607      0.488      0.528      0.362      0.572      0.458      0.457      0.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3         0G     0.8911      1.902      1.192      1.121         69        640: 100%|██████████| 13/13 [04:05<00:00, 18.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:23<00:00, 11.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         50        268      0.527        0.6      0.568       0.37      0.604      0.485      0.517       0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3         0G      0.904      1.809      1.061      1.146         86        640: 100%|██████████| 13/13 [04:06<00:00, 18.98s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:23<00:00, 11.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         50        268      0.505      0.559      0.507      0.367      0.457      0.558      0.444      0.255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.228 hours.\n",
      "Optimizer stripped from runs\\segment\\train2\\weights\\last.pt, 45.1MB\n",
      "Optimizer stripped from runs\\segment\\train2\\weights\\best.pt, 45.1MB\n",
      "\n",
      "Validating runs\\segment\\train2\\weights\\best.pt...\n",
      "Ultralytics 8.3.109  Python-3.12.4 torch-2.6.0+cpu CPU (AMD Ryzen 7 PRO 7840HS w/ Radeon 780M Graphics)\n",
      "YOLO11m-seg summary (fused): 138 layers, 22,336,854 parameters, 0 gradients, 123.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  50%|█████     | 1/2 [00:13<00:13, 13.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n",
      "WARNING  Limiting validation plots to first 50 items per image for speed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:20<00:00, 10.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         50        268      0.527      0.609      0.567       0.37      0.605      0.483      0.517       0.29\n",
      "                  Roof         37        195      0.594      0.697      0.661      0.457      0.714       0.61      0.665      0.393\n",
      "                 Solar         23         73      0.461      0.521      0.474      0.283      0.495      0.356      0.369      0.188\n",
      "Speed: 0.8ms preprocess, 373.4ms inference, 0.0ms loss, 10.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\segment\\train2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load the YOLO model as a starting point\n",
    "model = YOLO(\"yolo11m-seg.pt\")\n",
    "\n",
    "# Train the model on the dataset\n",
    "results = model.train(\n",
    "    data=\"config/config_train.yaml\",\n",
    "    epochs=3,\n",
    "    patience=0,\n",
    "    #classes=[0], # Set the class to train on 0=Roof 1=Solar. Remove this line to train on all classes\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17549aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffe06a39",
   "metadata": {},
   "source": [
    "# 02 - Test model on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26250d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model from training\n",
    "best_model = YOLO(\"runs/segment/train/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fcb6ba22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\thoma\\Documents\\GitHub\\WING_YOLO\\test_image.png: 448x640 13 Roofs, 261.9ms\n",
      "Speed: 1.7ms preprocess, 261.9ms inference, 10.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns\\segment\\predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# inference on an image\n",
    "results = best_model.predict(\n",
    "    source=\"test_image.png\",\n",
    "    save=True,\n",
    "    #show_boxes=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668ec687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f41725b6",
   "metadata": {},
   "source": [
    "# 03 - Prepare model for Depness\n",
    "https://qgis-plugin-deepness.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54c7d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = 'runs/segment/train8/weights/best.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297b4be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(path_to_model)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5f27b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the model as ONNX\n",
    "best_model.export(format=\"onnx\", dynamic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb32c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352e43ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ec7e0fb",
   "metadata": {},
   "source": [
    "https://qgis-plugin-deepness.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d1da6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
